<!DOCTYPE html>
<html>

<head>
    <style>
        body {
            text-align: center;
            font-family: Arial, sans-serif;
            background-color: #f0f0f0;
        }

        .container {
            width: 80%;
            margin: 0 auto;
            background-color: #fff;
            padding: 20px;
            border-radius: 10px;
            box-shadow: 0 0 10px rgba(0, 0, 0, 0.2);
        }

        img {
            display: block;
            margin: 0 auto;
        }

        h1 {
            font-size: 36px; /* Increased font size for the title */
            color: #000; /* Black text color */
            margin-top: 20px; /* Adding space between title and content */
        }

        h2 {
            font-size: 18px;
            color: #666;
        }

        h3 {
            font-size: 24px; /* Increased font size for sections */
            color: #000; /* Black text color */
            margin-top: 30px; /* Adding space between sections */
        }

        p {
            font-size: 16px;
            color: #333;
            text-align: left; /* Align text in paragraphs to the left */
        }
    </style>

    <title>ENG0018 Computer Laboratory 2023/24</title>
</head>

<body>
    <!-- Top section before the title -->
    <div class="container">
        <img src="WebBanner.png" alt="Banner" width="300" height="100">
        <h2>Student URN: 6807707</h2>
    </div>

    <!-- Divider between top section and title -->
    <hr style="border: 2px solid #000; margin-top: 30px;">

    <!-- Title section -->
    <div class="container">
        <h1><b>The Moral and Ethical Issues Behind Artificial Intelligence</b></h1>

        <h3><b>Abstract:</b></h3>
        <p>Artificial Intelligence (AI) poses significant moral and ethical dilemmas in contemporary society. 
        This article explores...</p>
        <!-- Your 150-word abstract goes here -->

        <h3><b>Main Article:</b></h3>
        <p>
            Artificial Intelligence (AI) has transitioned from a theoretical concept to a powerful force in modern society.
            Initially designed to replicate human intelligence, AI now permeates sectors of our daily lives, some namely
            recommendation systems, autonomous vehicles, healthcare, and financial domains. <a href="#ref1"><sup>[1]</sup></a>
            Russell and Norvig (2016) define AI as the development of algorithms and computer systems capable of executing
            tasks traditionally within the realm of human intelligence. The rapid expansion of AI technologies has enabled
            an era of progress alongside many ethical challenges. As articulated by <a href="#ref2"><sup>[2]</sup></a> Bostrom
            (2014), the swift advancement of AI capabilities has outpaced ethical deliberations, resulting in a myriad of
            ethical quandaries. These ethical concerns include biases from developers of an artificial intelligence,
            breaches of data privacy, and societal implications arising from automation, notably reducing employment the
            most. This article aims to delve into the ethical and moral impacts surrounding the evolution of AI. It
            navigates through the negative social effects posed by AI's great potential, emphasizing the necessity for
            ethical frameworks and societal contributions needed to guide AI development towards responsible and beneficial
            uses.
        </p>
        <p>
            Artificial Intelligence (AI) is everywhere now, but it has some big issues. One of the main problems is that
            AI can be biased, just like people. Buolamwini and Gebru (2018) found that AI can make unfair decisions,
            like favoring certain people for jobs or loans because of flawed data or how it's programmed. This unfairness
            raises questions about who should take responsibility for these biased decisions <a href="#ref1"><sup>[3]</sup></a>.
            These biases in AI aren't just technical mistakes; they bring up bigger questions about fairness and who's
            accountable. Figuring out who's to blame—whether it's the people who make AI, the data used, or the
            algorithms themselves—is a tough challenge. It's not just about fixing technology but setting up rules and
            ethical guidelines to make sure AI decisions are fair for everyone.
            Moreover, AI also raises concerns about privacy. Moor and Weckert (2019) point out how AI collects lots of our
            personal information without us knowing. This constant data collection can make us feel like our privacy is
            being invaded <a href="#ref2"><sup>[4]</sup></a>. AI uses this data for things like personalized ads or
            predictions, blurring the line between what's private and what's not.
            These issues around biases in AI, unfair decisions in hiring or loans, and the invasion of privacy show why we
            need clear rules and ethical guidelines for AI. It's not just about fixing technical errors but making sure
            AI treats everyone fairly and respects our privacy. Creating fair and responsible AI means setting up rules
            that protect everyone's rights and privacy without letting biases affect important decisions.
        </p>
        <p>
            The rise of Artificial Intelligence (AI) brings worries about job loss. Frey and Osborne (2017) explain how AI
            might take over many tasks, making some jobs unnecessary. This could cause big changes in how jobs work and
            make the gap between rich and poor even bigger <a href="#ref1"><sup>[5]</sup></a>.
            AI is good at doing repetitive tasks really fast. A study by PWC (PriceWaterhouseCoopers) shows that about
            30% of jobs in the UK could be done by AI by the early 2030s (As seen in figure 1 below) <a href="#ref2"><sup>[6]</sup></a>. This could affect jobs in areas like
            transportation, manufacturing, and office work, leaving many people without work.
            This job disruption might not only affect individual jobs but also make inequality worse. People in jobs that
            AI can easily do might have a harder time finding new work. This could make the difference between rich and
            poor even wider. To tackle this, it's important to help people gain new skills to fit in the changing job
            market.
            Dealing with these changes needs different actions. Governments should make rules that help balance new
            technology with keeping jobs stable. Schools and training programs should focus on teaching skills that work
            well with AI, so people can use this technology better. Partnerships between industries, schools, and
            governments are key to helping people adapt to these changes by offering training and support for finding new
            jobs.
            Ultimately, the worry about AI taking jobs means we need to work together to prepare for these changes.
            Governments, schools, and industries need to collaborate to make sure everyone can benefit from AI without
            losing their livelihoods.
            <br><br>
            <b><i>Figure 1: Employment Impact of AI in the UK by 2030s</i></b>
            <img src="employment.jpg" alt="Employment Impact" width="800" height="300">
            <br><br>
            PWC's study shows how AI might reduce jobs in the future. This image illustrates the potential impact on
            employment due to AI advancements.
        </p>

        <h3><b>References:</b></h3>
        <p>
            <a id="ref1"></a><sup>[1]</sup> Russell, S., & Norvig, P. (2016). Artificial Intelligence: A Modern
            Approach. Pearson. <br>
            <a id="ref2"></a><sup>[2]</sup> Bostrom, N. (2014). Superintelligence: Paths, Dangers, Strategies. Oxford
            University Press. <br>
            <a id="ref1"></a><sup>[3]</sup> Buolamwini, J., & Gebru, T. (2018). Gender Shades: Intersectional
            Accuracy Disparities in Commercial Gender Classification. Conference on Fairness, Accountability and
            Transparency. <br>
            <a id="ref2"></a><sup>[4]</sup> Moor, J. H., & Weckert, J. (2019). Robot Ethics 2.0: From Autonomous Cars
            to Artificial Intelligence. Oxford University Press. <br>
            <a id="ref1"></a><sup>[5]</sup> Frey, C. B., & Osborne, M. A. (2017). The Future of Employment: How
            Susceptible Are Jobs to Computerisation? Technological Forecasting and Social Change.
            <br>
            <a id="ref2"></a><sup>[6]</sup> PriceWaterhouseCoopers (PWC). (2020). Automation will impact around 30% of UK jobs by mid 2030s - but which ones?. Retrieved from
            <a href="https://www.pwc.co.uk/press-room/press-releases/regions/northern-ireland/automation-impact.html">https://www.pwc.co.uk/press-room/press-releases/regions/northern-ireland/automation-impact.html</a>
        </p>
        </p>
    </div>

</body>

</html>
